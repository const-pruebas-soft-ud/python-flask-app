# Pruebas Unitarias - Python Flask App

Este documento describe las pruebas unitarias implementadas para la aplicaciÃ³n Flask.

## ğŸ§ª Pruebas Implementadas

El archivo `tests/test_app.py` contiene las siguientes pruebas:

### 1. **Pruebas de Rutas BÃ¡sicas**
- âœ… `test_index_route`: Verifica que la pÃ¡gina principal carga correctamente
- âœ… `test_favicon_route`: Verifica que el favicon se sirve correctamente

### 2. **Pruebas del Contador de Visitas**
- âœ… `test_index_visit_counter`: Verifica que el contador de visitas incrementa
- âœ… `test_multiple_visits_increment`: Verifica mÃºltiples visitas

### 3. **Pruebas de Funcionalidad de Saludo**
- âœ… `test_hello_with_name`: Verifica que el saludo funciona con un nombre
- âœ… `test_hello_without_name`: Verifica la redirecciÃ³n sin nombre
- âœ… `test_hello_without_name_follow_redirect`: Verifica el comportamiento de redirecciÃ³n
- âœ… `test_hello_greeting_counter`: Verifica que el contador de saludos incrementa
- âœ… `test_multiple_greetings_increment`: Verifica mÃºltiples saludos

## ğŸš€ Ejecutar las Pruebas Localmente

### Instalar Dependencias
```bash
pip install -r requirements.txt
```

### Ejecutar Todas las Pruebas
```bash
pytest tests/
```

### Ejecutar con Cobertura
```bash
pytest tests/ --cov=. --cov-report=html --cov-report=term
```

### Ver Reporte de Cobertura
DespuÃ©s de ejecutar las pruebas con cobertura, abre:
```bash
# Windows
start htmlcov/index.html

# Linux/Mac
open htmlcov/index.html
```

## ğŸ“Š Cobertura de CÃ³digo

Las pruebas estÃ¡n configuradas para generar reportes de cobertura en tres formatos:
- **Terminal**: Muestra un resumen en la consola
- **XML**: Para integraciÃ³n con SonarQube (`coverage.xml`)
- **HTML**: Para visualizaciÃ³n detallada (`htmlcov/`)

## ğŸ”„ IntegraciÃ³n con GitHub Actions

Las pruebas se ejecutan automÃ¡ticamente en GitHub Actions:

1. **Build and Test**: Ejecuta pytest con cobertura
2. **SonarQube**: Analiza el cÃ³digo y la cobertura
3. **Deploy**: Solo se ejecuta si las pruebas pasan

## ğŸ“ Agregar Nuevas Pruebas

Para agregar nuevas pruebas:

1. Crea una funciÃ³n en `tests/test_app.py` con el prefijo `test_`
2. Usa el fixture `client` para simular peticiones HTTP
3. Ejecuta las pruebas localmente antes de hacer commit

Ejemplo:
```python
def test_nueva_funcionalidad(client):
    """DescripciÃ³n de la prueba"""
    response = client.get('/nueva-ruta')
    assert response.status_code == 200
    assert b'Contenido esperado' in response.data
```

## ğŸ› ï¸ Comandos Ãštiles

```bash
# Ejecutar una prueba especÃ­fica
pytest tests/test_app.py::test_index_route

# Ejecutar con modo verbose
pytest tests/ -v

# Ejecutar y mostrar print statements
pytest tests/ -s

# Ejecutar y detener en el primer error
pytest tests/ -x

# Ver quÃ© pruebas se ejecutarÃ¡n sin ejecutarlas
pytest tests/ --collect-only
```

## ğŸ“¦ Dependencias de Pruebas

- `pytest==8.3.3`: Framework de pruebas
- `pytest-cov==6.0.0`: Plugin de cobertura para pytest

## ğŸ¯ Objetivos de Cobertura

Se recomienda mantener una cobertura de cÃ³digo de al menos:
- **80%** para cÃ³digo general
- **90%** para funciones crÃ­ticas de negocio
